{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MBartTokenizer, MBartModel, MBartForConditionalGeneration\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch\n",
    "import data_prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing English to French\n",
      "Preparing English to Spanish\n",
      "Preparing English to Chinese\n",
      "Downloading and preparing dataset csv/default to /home/vg2565/.cache/huggingface/datasets/csv/default-05fc7f3b10286f96/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ca745c4c4b4fa29dee675ecdaa376b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b161696dda4e439e7c8fd62716bded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7992f41734d4da2a6b07d58325b6457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/vg2565/.cache/huggingface/datasets/csv/default-05fc7f3b10286f96/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc41830e1e8411aa102fd94d7367bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3445163ac99949f6b72f140f340f318a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8871abb3864c0db7501e2766541da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0c32c6c7bc4d4ead7713a73826c46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/vg2565/.cache/huggingface/datasets/csv/default-dae19ca5587d224e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc58223fc9e34b599421c853c56a9dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745ccefecff44a679517ecedcda7b002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14523bdd48f3479ab58c01b4e64226dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/vg2565/.cache/huggingface/datasets/csv/default-dae19ca5587d224e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6028c54c6ef4410aadb196eedf4fe8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d48f0fc3c44041a0b869aa748f3bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f24c6d80a44c548b92e94a8570d20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb6b52662784b829ffa3443374d3339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/vg2565/.cache/huggingface/datasets/csv/default-f03cdcc0d65998f2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d577d42a807b46918af743d476dc06c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2eeb64b13ee497fb17e8fb808e6b8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8401a6db709344ff88e529cc8dc2f1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/vg2565/.cache/huggingface/datasets/csv/default-f03cdcc0d65998f2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb9eba55da64c3ebd27c2fa28115c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43085bce3354a9fa9c8f5dfe8a30eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313a155b84ae490d92aacf39406e74a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecdfb8a1cbd470981edb07399f3e8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_prep.create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/mbart-large-cc25 were not used when initializing MBartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MBartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MBartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_mbart_cc25 = MBartModel.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "tokenizer_mbart_cc25_fr = MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\", src_lang=\"en_XX\", tgt_lang=\"fr_XX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610851840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mbart_cc25.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/vg2565/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395d888f40af4cf597fdd249b48c58c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_datasets[\"train\"][0]\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "# tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "# tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_en_fr = load_from_disk(\"./data/en-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Allah is the Light of the heavens and the earth.',\n",
       " 'They wear mourning for seven full days, after which they put it off.',\n",
       " 'They can also send them as messages that destroy themselves in 48 hours.',\n",
       " '\"Moganite: a New Mineral -- Not!\".',\n",
       " 'Dečko koji obećava Sretno dijete Outsider Bilo jednom...',\n",
       " 'The Night of Power is better than a thousand months.',\n",
       " 'Until then his family thought he had died in the mountains.',\n",
       " \"(Commercial) Raymond: Well, we're about to begin our story.\",\n",
       " 'Night hath better sweets to prove, Venus now wakes, and wakens Love.',\n",
       " '(Contemporary, 1957 ) The Poll Winners Ride Again!',\n",
       " 'Foa, E. After Big Game in Central Africa.',\n",
       " 'I may be a mere scholar, but I have received orders from our Lord.',\n",
       " 'I know that for America there will always be a bright dawn ahead.',\n",
       " 'Hip-Hop Alive and Well on the Web.',\n",
       " 'RICE: You said did it not warn of attacks.',\n",
       " 'I do not believe you acted in defense of Major Umbach or yourself.',\n",
       " 'Katherine Rogers\\xa0: Can Christianity be Proven?',\n",
       " '\"U2 shows its star power\".',\n",
       " 'A Question Book (1927) Do you Know Your History?',\n",
       " 'Such is the command of Allah.',\n",
       " 'In: Die Wahrheit ist nackt am schönsten.',\n",
       " '보고싶어 많이많이 Guyz how do u do~we miss u so so much..Thanks 4 waiting us.',\n",
       " 'K. 45a was probably among these six.',\n",
       " '\"Stefani has it all, baby\".',\n",
       " 'Aux gens de loi tu couperas les ongles radicalement.',\n",
       " '100 Masterpieces with and through Media.',\n",
       " 'I must correct him on that: Finland is a member of the EU.',\n",
       " 'Satan was expelled from Heaven and sent to Earth.',\n",
       " \"That's why some or many have not seen many Tweets from me.\",\n",
       " 'Death will take away only what we wanted to possess.',\n",
       " 'Mankind, awake!',\n",
       " 'In December 1998 Jag rear ut min själ!',\n",
       " '\"I got a little greedy.',\n",
       " 'Why snakes have forked tongues.',\n",
       " 'In water iron then shall float, As easy as a wooden boat.',\n",
       " 'In Algeria you\\'ve got such pretty sheep, why don\\'t you talk about your sheep?\").',\n",
       " '\"Who Are These Independent Information Brokers?\"',\n",
       " 'You Can Be an Oni, too!!',\n",
       " 'Within 20 years, there will be more reasons to be proud of being Japanese, than of being European.',\n",
       " 'To South Dakota we welcome you.',\n",
       " 'You could see more of the roof of the plane than you could the belly.',\n",
       " 'Jawahir-al-Galam Ajaib-ul-Quran.',\n",
       " 'En mort de qualité, je lui tins ce langage.',\n",
       " 'I know that you understand the challenge we are facing.',\n",
       " 'Waterbury, John, et al. Little Things Matter A Lot.',\n",
       " '\"Experts: The Bailout Worked!',\n",
       " 'But Allah tells (you) the Truth, and He shows the (right) Way.',\n",
       " 'So fear not mankind, but fear Me.',\n",
       " 'But that\\'s the same girl I saw every day at the drop zone.\"',\n",
       " 'Now we have rules on this Power Board here, ok?',\n",
       " \"(1995) Who's Number 1 in College Football?...And How Might We Decide?\",\n",
       " '(1546) Love me, love my dog.',\n",
       " 'We did achieve our design goals....',\n",
       " \"Because I don't want the best tattoo shop in New York, I want the best shop in the world.\",\n",
       " 'I swear by Allah that they will have their days...',\n",
       " '\"Perryville at one time Regular Military Post.\"',\n",
       " 'I will cheerfully and willingly obey all lawful orders.',\n",
       " 'We need more heroines like you, Tina.',\n",
       " '\"Sorry her lot who loves too well\" (Josephine) 5a.',\n",
       " 'They are subservient to him, and created for a purely practical end.',\n",
       " 'Sections 7-13 discuss further related issues.',\n",
       " 'One of the best in a year of many gems.',\n",
       " 'Let us remain Estonians, but let us become Europeans too.',\n",
       " \"From the Back of the Bus What's Happening?\",\n",
       " 'The Chicago report precedes the full purchasing agents report.',\n",
       " 'Wide Boys Never Work.',\n",
       " '\"Wampas Ex-Baby Lives on WPA $23 – And Likes It.\"',\n",
       " 'Trolderim Mit stamtræ Hvad brugte vi ilden til\\xa0?',\n",
       " 'All crimes begin with a lie as we say in Japan.',\n",
       " 'If Elvis can do it, I can do it.',\n",
       " 'Senden İbaret (2000) Sen Yoluna...',\n",
       " 'So Much \"junk\" DNA in Our Genome.',\n",
       " 'L’étrange destinée d’un homme trois fois français.',\n",
       " 'This is the biggest weakness of Chinese TV and I hate it!',\n",
       " '2030 is a dream and a goal.\"',\n",
       " 'Jesus will lose none of his sheep.',\n",
       " 'Our Funding Process Has Begu... wait.',\n",
       " 'Because they are her creation.',\n",
       " 'There is a dispute among the scholars concerning some of the dates, and not all is agreed upon.',\n",
       " '1965\\xa0– You Better Run.',\n",
       " 'Then we did not want you to go to the Senate but the people would send you.\"',\n",
       " 'Sermon 111, mentions some attributes to Allah.',\n",
       " 'With black and white, you can really see who they are.',\n",
       " 'As if there even were a Tunisian personality!',\n",
       " 'Se pudésseis aqui ver poesia que não há!\"',\n",
       " 'On what wings dare he aspire?',\n",
       " '2012 - Lado a Lado ....',\n",
       " '\"Why Do Europeans Have So Many Hair and Eye Colors?\" (summarizing Frost, P. 2006.',\n",
       " 'Do you think the night can furnish no pleasure?\"',\n",
       " 'For our children and for you, Samantha.',\n",
       " 'Quand la France vendait son opium.',\n",
       " '52 minute 2007 Buscapé.',\n",
       " 'Say Na Something to Anupam Uncle.',\n",
       " 'It is also entirely possible that North Korea is lying.',\n",
       " '\"Elegy XIX: To His Mistress Going to Bed\".',\n",
       " 'Allah hath made it come true!',\n",
       " '\"Soldier Like Me (Return of the Soulja)\" 02.',\n",
       " 'Wild Flowers Worth Knowing.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_en_fr[\"train\"][\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/vg2565/Project/High-Performance-ML-Project/MBart/data/en-fr/train/cache-45a7bd307e2c4faf.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/vg2565/Project/High-Performance-ML-Project/MBart/data/en-fr/test/cache-e9afb5d197732e06.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/vg2565/Project/High-Performance-ML-Project/MBart/data/en-fr/valid/cache-83aee51047dae918.arrow\n"
     ]
    }
   ],
   "source": [
    "src_lang, trg_lang = 'en', 'fr'\n",
    "tokenizer = tokenizer_mbart_cc25_fr\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [examples[src_lang]]\n",
    "    targets = [examples[trg_lang]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset_en_fr = dataset_en_fr.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       " 'test': ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       " 'valid': ['en', 'fr', 'input_ids', 'attention_mask', 'labels']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_en_fr.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 60\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_en_fr[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"model_outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_mbart_cc25,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_en_fr[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_en_fr[\"valid\"],\n",
    "    tokenizer=tokenizer_mbart_cc25_fr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
